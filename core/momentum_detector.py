"""
Motor Principal de Detecci√≥n de Momentum v2.0
Coordina el an√°lisis completo: Hist√≥rico + T√©cnico + Confluencia = Se√±al Final
"""

import asyncio
from typing import Dict, List, Optional
from datetime import datetime

from core.historical_analyzer import HistoricalAnalyzer
from core.technical_analyzer import TechnicalAnalyzer
from indicators.confluence_validator import ConfluenceValidator
from core.signal_unifier import SignalUnifier
from config.parameters import TARGET_DAILY_SIGNALS, TARGET_MOVEMENT
from utils.logger import log


class MomentumDetector:
    """
    Motor principal que coordina todo el an√°lisis de momentum.
    Integra las 3 secciones principales para generar se√±ales finales.
    """
    
    def __init__(self):
        # Inicializar componentes principales
        self.historical_analyzer = HistoricalAnalyzer()
        self.technical_analyzer = TechnicalAnalyzer()
        self.confluence_validator = ConfluenceValidator()
        self.signal_unifier = SignalUnifier()
        
        # Estado del detector
        self.analysis_count = 0
        self.last_analysis_time = None
        self.detected_opportunities: Dict[str, Dict] = {}
        self.daily_signals_count = 0
        
        # Cache para optimizar an√°lisis
        self.symbol_cache: Dict[str, Dict] = {}
        self.cache_duration = 300  # 5 minutos
        
    async def detect_momentum_opportunities(self, market_data: Dict) -> List[Dict]:
        """
        Detecta oportunidades de momentum en el mercado completo.
        
        Args:
            market_data: Dict con datos de todos los s√≠mbolos del mercado
            
        Returns:
            List de oportunidades ordenadas por score total
        """
        try:
            log.info(f"üîç Iniciando detecci√≥n de momentum para {len(market_data)} s√≠mbolos")
            
            opportunities = []
            analysis_tasks = []
            
            # Crear tareas de an√°lisis en paralelo (limitado para no sobrecargar)
            semaphore = asyncio.Semaphore(10)  # M√°ximo 10 an√°lisis concurrentes
            
            for symbol, symbol_data in market_data.items():
                if self._should_analyze_symbol(symbol, symbol_data):
                    task = self._analyze_symbol_with_semaphore(
                        semaphore, symbol, symbol_data
                    )
                    analysis_tasks.append(task)
            
            # Ejecutar an√°lisis en paralelo
            if analysis_tasks:
                log.info(f"üöÄ Analizando {len(analysis_tasks)} s√≠mbolos en paralelo")
                results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
                
                # Procesar resultados
                for result in results:
                    if isinstance(result, Exception):
                        log.error(f"Error en an√°lisis paralelo: {result}")
                        continue
                    
                    if result and result.get('total_score', 0) > 0:
                        opportunities.append(result)
            
            # Ordenar por score total (descendente)
            opportunities.sort(key=lambda x: x.get('total_score', 0), reverse=True)
            
            # Actualizar estado
            self.analysis_count += 1
            self.last_analysis_time = datetime.now()
            
            # Filtrar mejores oportunidades
            top_opportunities = self._filter_top_opportunities(opportunities)
            
            log.info(f"‚úÖ Detecci√≥n completada: {len(top_opportunities)}/{len(opportunities)} oportunidades seleccionadas")
            
            return top_opportunities
            
        except Exception as e:
            log.error(f"Error en detecci√≥n de momentum: {e}")
            return []
    
    async def _analyze_symbol_with_semaphore(self, semaphore: asyncio.Semaphore,
                                           symbol: str, symbol_data: Dict) -> Optional[Dict]:
        """Analiza un s√≠mbolo con control de concurrencia"""
        async with semaphore:
            return await self.analyze_symbol_complete(symbol, symbol_data)
    
    async def analyze_symbol_complete(self, symbol: str, symbol_data: Dict) -> Optional[Dict]:
        """
        An√°lisis completo de un s√≠mbolo: Hist√≥rico + T√©cnico + Confluencia + Unificaci√≥n
        
        Args:
            symbol: S√≠mbolo a analizar
            symbol_data: Datos completos del s√≠mbolo
            
        Returns:
            Dict con an√°lisis completo y se√±al unificada, o None si no hay oportunidad
        """
        try:
            log.debug(f"üìä An√°lisis completo iniciado para {symbol}")
            
            # Verificar cache
            cached_result = self._get_cached_analysis(symbol)
            if cached_result:
                log.debug(f"üìã Usando an√°lisis cacheado para {symbol}")
                return cached_result
            
            # 1. SECCI√ìN 1: An√°lisis Hist√≥rico (0-25 puntos)
            log.debug(f"üìà An√°lisis hist√≥rico {symbol}")
            historical_result = self.historical_analyzer.analyze_symbol_history(
                symbol, symbol_data.get('historical_data', {})
            )
            
            # 2. SECCI√ìN 2: An√°lisis T√©cnico (0-50 puntos)
            log.debug(f"‚öôÔ∏è An√°lisis t√©cnico {symbol}")
            technical_result = await self.technical_analyzer.analyze_symbol_technicals(
                symbol, symbol_data.get('current_data', {})
            )
            
            # 3. CONFLUENCIA Multi-Timeframe (0-25 puntos)
            log.debug(f"üîó An√°lisis confluencia {symbol}")
            confluence_result = await self.confluence_validator.validate_multi_timeframe_confluence(
                symbol, symbol_data.get('timeframe_data', {})
            )
            
            # 4. UNIFICACI√ìN: Combinar las 3 secciones
            log.debug(f"üéØ Unificando se√±ales {symbol}")
            unified_signal = self.signal_unifier.unify_signals(
                symbol, historical_result, technical_result, confluence_result
            )
            
            # Verificar si es una oportunidad v√°lida
            if self._is_valid_opportunity(unified_signal):
                # Cachear resultado
                self._cache_analysis(symbol, unified_signal)
                
                log.info(f"‚úÖ Oportunidad detectada: {self.signal_unifier.get_signal_summary(unified_signal)}")
                return unified_signal
            else:
                log.debug(f"‚ùå {symbol} no cumple criterios m√≠nimos")
                return None
                
        except Exception as e:
            log.error(f"Error en an√°lisis completo {symbol}: {e}")
            return None
    
    def _should_analyze_symbol(self, symbol: str, symbol_data: Dict) -> bool:
        """Determina si un s√≠mbolo debe ser analizado"""
        try:
            # Filtros b√°sicos
            if not symbol.endswith('USDT'):
                return False
            
            # Verificar volumen m√≠nimo
            volume_24h = symbol_data.get('volume_24h', 0)
            if volume_24h < 1_000_000:  # $1M m√≠nimo
                return False
            
            # Verificar precio dentro de rango
            current_price = symbol_data.get('price', 0)
            if current_price < 0.01 or current_price > 1000:
                return False
            
            # Verificar que tengamos datos suficientes
            required_data = ['historical_data', 'current_data', 'timeframe_data']
            for data_type in required_data:
                if data_type not in symbol_data or not symbol_data[data_type]:
                    return False
            
            return True
            
        except Exception as e:
            log.error(f"Error verificando s√≠mbolo {symbol}: {e}")
            return False
    
    def _is_valid_opportunity(self, signal: Dict) -> bool:
        """Determina si una se√±al unificada es una oportunidad v√°lida"""
        try:
            # Criterios m√≠nimos para considerar oportunidad
            total_score = signal.get('total_score', 0)
            confidence_level = signal.get('confidence_level', 'D√âBIL')
            recommendation = signal.get('recommendation', 'HOLD')
            
            # Score m√≠nimo
            if total_score < 30:
                return False
            
            # Solo se√±ales de compra o vigilancia fuerte
            if recommendation not in ['STRONG_BUY', 'BUY', 'WEAK_BUY', 'WATCH']:
                return False
            
            # Para se√±ales d√©biles, requerir score m√°s alto
            if confidence_level == 'D√âBIL' and total_score < 40:
                return False
            
            # Verificar que no haya errores cr√≠ticos
            if 'error' in signal:
                return False
            
            return True
            
        except Exception as e:
            log.error(f"Error validando oportunidad: {e}")
            return False
    
    def _filter_top_opportunities(self, opportunities: List[Dict]) -> List[Dict]:
        """Filtra las mejores oportunidades seg√∫n criterios de calidad"""
        try:
            if not opportunities:
                return []
            
            # Separar por nivel de confianza
            strong_signals = [op for op in opportunities if op.get('confidence_level') == 'FUERTE']
            high_signals = [op for op in opportunities if op.get('confidence_level') == 'ALTO']
            medium_signals = [op for op in opportunities if op.get('confidence_level') == 'MEDIO']
            
            # Seleccionar las mejores de cada categor√≠a
            top_opportunities = []
            
            # Todas las se√±ales fuertes (m√°ximo 5)
            top_opportunities.extend(strong_signals[:5])
            
            # Mejores se√±ales altas (m√°ximo 3 adicionales)
            remaining_slots = TARGET_DAILY_SIGNALS - len(top_opportunities)
            if remaining_slots > 0:
                top_opportunities.extend(high_signals[:min(3, remaining_slots)])
            
            # Si a√∫n tenemos espacio, agregar mejores se√±ales medias
            remaining_slots = TARGET_DAILY_SIGNALS - len(top_opportunities)
            if remaining_slots > 0:
                # Solo se√±ales medias con score alto
                high_medium_signals = [op for op in medium_signals if op.get('total_score', 0) >= 60]
                top_opportunities.extend(high_medium_signals[:remaining_slots])
            
            # Limitar a objetivo diario + margen
            max_signals = TARGET_DAILY_SIGNALS + 2  # Margen de 2 se√±ales adicionales
            return top_opportunities[:max_signals]
            
        except Exception as e:
            log.error(f"Error filtrando oportunidades: {e}")
            return opportunities[:TARGET_DAILY_SIGNALS]
    
    def _get_cached_analysis(self, symbol: str) -> Optional[Dict]:
        """Obtiene an√°lisis cacheado si est√° vigente"""
        try:
            if symbol not in self.symbol_cache:
                return None
            
            cached_data = self.symbol_cache[symbol]
            cache_time = cached_data.get('cache_time')
            
            if cache_time:
                elapsed = (datetime.now() - cache_time).total_seconds()
                if elapsed < self.cache_duration:
                    return cached_data.get('analysis')
            
            # Cache expirado, eliminar
            del self.symbol_cache[symbol]
            return None
            
        except Exception as e:
            log.error(f"Error obteniendo cache {symbol}: {e}")
            return None
    
    def _cache_analysis(self, symbol: str, analysis: Dict):
        """Cachea an√°lisis para evitar rec√°lculos"""
        try:
            self.symbol_cache[symbol] = {
                'analysis': analysis,
                'cache_time': datetime.now()
            }
            
            # Limpiar cache viejo
            self._cleanup_cache()
            
        except Exception as e:
            log.error(f"Error cacheando an√°lisis {symbol}: {e}")
    
    def _cleanup_cache(self):
        """Limpia entradas de cache expiradas"""
        try:
            current_time = datetime.now()
            expired_symbols = []
            
            for symbol, data in self.symbol_cache.items():
                cache_time = data.get('cache_time')
                if cache_time:
                    elapsed = (current_time - cache_time).total_seconds()
                    if elapsed >= self.cache_duration:
                        expired_symbols.append(symbol)
            
            for symbol in expired_symbols:
                del self.symbol_cache[symbol]
                
        except Exception as e:
            log.error(f"Error limpiando cache: {e}")
    
    async def get_analysis_summary(self) -> Dict:
        """Obtiene resumen del estado actual del detector"""
        try:
            # Se√±ales fuertes del d√≠a
            strong_signals = self.signal_unifier.get_strong_signals_today()
            
            # Estad√≠sticas
            cache_size = len(self.symbol_cache)
            
            summary = {
                'analysis_count': self.analysis_count,
                'last_analysis': self.last_analysis_time,
                'daily_strong_signals': len(strong_signals),
                'cache_size': cache_size,
                'detected_opportunities': len(self.detected_opportunities),
                'target_daily_signals': TARGET_DAILY_SIGNALS,
                'target_movement': f"+{TARGET_MOVEMENT}%"
            }
            
            return summary
            
        except Exception as e:
            log.error(f"Error generando resumen: {e}")
            return {}
    
    async def force_analysis_refresh(self):
        """Fuerza actualizaci√≥n de an√°lisis limpiando cache"""
        try:
            self.symbol_cache.clear()
            log.info("üîÑ Cache de an√°lisis limpiado - pr√≥ximo an√°lisis ser√° completo")
            
        except Exception as e:
            log.error(f"Error refrescando an√°lisis: {e}")
    
    def get_top_opportunities_summary(self, count: int = 5) -> List[str]:
        """Obtiene resumen textual de las mejores oportunidades"""
        try:
            recent_signals = self.signal_unifier.get_recent_signals(count * 2)
            
            # Filtrar y ordenar por score
            valid_signals = [s for s in recent_signals if s.get('total_score', 0) >= 50]
            valid_signals.sort(key=lambda x: x.get('total_score', 0), reverse=True)
            
            summaries = []
            for signal in valid_signals[:count]:
                summary = self.signal_unifier.get_signal_summary(signal)
                summaries.append(summary)
            
            return summaries
            
        except Exception as e:
            log.error(f"Error generando res√∫menes: {e}")
            return []
